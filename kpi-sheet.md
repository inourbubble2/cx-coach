# KPI 시트 - 상담 코칭 시스템 (Counsel Coach)

**버전**: 1.0  
**작성일**: 2026-01-29  
**작성자**: FDE 지원자

---

## 1. KPI 프레임워크 개요

### 1.1 지표 선정 원칙

이 KPI 시트는 **채널톡 FDE 역할의 핵심 가치**를 기반으로 설계되었습니다:

1. **고객 현장의 문제 해결**: 실제로 상담 품질이 개선되는가?
2. **스케일러블한 솔루션**: 비용 효율적으로 확장 가능한가?
3. **제품화 가능성**: 검증된 프로토타입으로서 가치가 있는가?

### 1.2 지표 분류 체계

```
                    ┌─────────────────────────────────────────┐
                    │           Business Impact               │
                    │      (비즈니스 임팩트 지표)               │
                    │                                         │
                    │  "실제로 고객사의 문제를 해결했는가?"       │
                    └─────────────────────────────────────────┘
                                       ▲
                                       │
                    ┌─────────────────────────────────────────┐
                    │           Product Quality               │
                    │         (제품 품질 지표)                 │
                    │                                         │
                    │    "시스템이 제대로 작동하는가?"           │
                    └─────────────────────────────────────────┘
                                       ▲
                                       │
                    ┌─────────────────────────────────────────┐
                    │           Operational Health            │
                    │          (운영 건전성 지표)              │
                    │                                         │
                    │   "지속 가능하게 운영되고 있는가?"         │
                    └─────────────────────────────────────────┘
```

---

## 2. 핵심 지표 (Key Metrics)

### 2.1 Business Impact (비즈니스 임팩트)

#### BI-1. 상담 품질 향상률 (Quality Improvement Rate)

| 항목 | 내용 |
|------|------|
| **정의** | 코칭 시스템 사용 전후 및 전월 대비 상담 품질 점수의 변화율 |
| **공식** | `(당월 평균 점수 - 전월 평균 점수) / 전월 평균 점수 × 100` |
| **목표** | ≥15% 향상 (MoM) |
| **측정 주기** | 월간 |
| **데이터 소스** | 분석 결과 DB (Supabase), RAGAs 평가 지표 |

**선정 이유**:
> 이 시스템의 궁극적 목표는 "상담원의 상담 품질 향상"입니다. 단순히 분석을 제공하는 것이 아니라, 실제로 상담 품질이 개선되었는지가 비즈니스 가치를 증명합니다. 채널톡 FDE로서 "현장에서 검증된 솔루션"을 만들기 위해 가장 중요한 지표입니다.

**측정 방법**:
```
1. 도입 전: 전문가가 무작위 상담 50건 평가 → 평균 점수 산출
2. 도입 후 1개월: 동일 방식으로 50건 재평가
3. 변화율 계산 및 통계적 유의성 검증
```

---

#### BI-2. 코칭 시간 절감률 (Coaching Time Reduction)

| 항목 | 내용 |
|------|------|
| **정의** | 매니저의 코칭 준비 및 실행에 소요되는 시간 감소율 |
| **공식** | `(기존 코칭 시간 - 현재 코칭 시간) / 기존 코칭 시간 × 100` |
| **목표** | ≥70% 절감 |
| **측정 주기** | 월간 |
| **데이터 소스** | 매니저 인터뷰, 시간 트래킹 |

**선정 이유**:
> 매니저의 Pain Point 중 하나는 "코칭 준비 시간이 코칭 시간보다 더 오래 걸린다"는 것입니다. AI가 분석과 피드백 초안을 제공함으로써 매니저가 더 많은 상담원을 코칭하거나, 더 깊이 있는 코칭에 집중할 수 있습니다.

**측정 방법**:
```
1. 도입 전: 매니저에게 코칭 1건당 소요 시간 기록 요청 (2주간)
   - 상담 청취/검토 시간
   - 피드백 작성 시간
   - 코칭 미팅 시간
2. 도입 후: 동일 방식으로 기록
3. 절감률 계산
```

---

#### BI-3. 상담원 자기주도 학습률 (Self-Learning Adoption)

| 항목 | 내용 |
|------|------|
| **정의** | 상담원이 자발적으로 본인 상담을 분석하는 비율 |
| **공식** | `자가 분석 요청 건수 / 전체 상담 건수 × 100` |
| **목표** | ≥10% (월간) |
| **측정 주기** | 주간 |
| **데이터 소스** | 시스템 사용 로그 |

**선정 이유**:
> 진정한 품질 향상은 상담원 스스로가 개선하고자 할 때 일어납니다. 매니저의 지시가 아닌, 상담원의 자발적 활용이 늘어난다면 시스템이 실제 가치를 제공하고 있다는 증거입니다.

---

### 2.2 Product Quality (제품 품질)

#### PQ-1. RAGAs 기반 분석 정확도 (Analysis Accuracy)

| 항목 | 내용 |
|------|------|
| **정의** | RAGAs (LLM-as-a-judge) 프레임워크를 통한 생성 답변 및 분석의 충실도/관련성 평가 |
| **핵심 지표**| **Faithfulness**: 질문/문맥에 기반한 답변의 사실적 정확도<br>**Answer Relevance**: 질문에 대한 답변의 관련성<br>**Context Precision**: 검색된 문맥의 유효성 |
| **목표** | 모든 RAGAs 지표 평균 ≥ 0.85 |
| **측정 주기** | 월간 |
| **데이터 소스** | RAGAs Evaluation Pipeline |

**선정 이유**:
> RAGAs는 사람이 직접 평가하기 어려운 대규모 데이터셋에 대해 일관된 기준(LLM-as-a-judge)으로 품질을 측정할 수 있게 해줍니다. 

**측정 방법**:
```
1. LLM으로 생성한 테스트 데이터셋(QnA Match) 준비
2. RAGAs 라이브러리를 통해 Faithfulness, Relevance 등 점수 자동 산출
3. 시뮬레이션 결과와 전문가 샘플링 검증 병행
```

---

#### PQ-2. 분석 완료율 (Analysis Completion Rate)

| 항목 | 내용 |
|------|------|
| **정의** | 업로드된 파일 중 정상적으로 분석이 완료된 비율 |
| **공식** | `성공적 분석 건수 / 전체 업로드 건수 × 100` |
| **목표** | ≥95% |
| **측정 주기** | 일간 |
| **데이터 소스** | 시스템 로그 |

**선정 이유**:
> 시스템 안정성의 기본 지표입니다. 분석 실패가 빈번하면 사용자 신뢰를 잃고 이탈합니다.

---

#### PQ-3. 평균 처리 시간 (Average Processing Time)

| 항목 | 내용 |
|------|------|
| **정의** | 파일 업로드부터 분석 결과 표시까지 소요 시간 |
| **측정 단위** | 초 (seconds) |
| **목표** | ≤30초 (텍스트), ≤60초 (음성 5분 기준) |
| **측정 주기** | 실시간 (P50, P95, P99) |
| **데이터 소스** | 시스템 로그 |

**선정 이유**:
> 사용자 경험에 직접적인 영향을 미칩니다. 30초가 넘으면 사용자가 이탈하거나 재시도합니다.

---

#### PQ-4. 피드백 실행가능성 점수 (Actionability Score)

| 항목 | 내용 |
|------|------|
| **정의** | 제시된 개선 피드백이 실제로 적용 가능한지에 대한 사용자 평가 |
| **측정 방법** | 분석 후 "이 피드백이 도움이 되었나요?" 설문 (1-5점) |
| **목표** | ≥4.0/5.0 |
| **측정 주기** | 월간 |
| **데이터 소스** | 인앱 설문 |

**선정 이유**:
> "문제점 지적"만으로는 부족합니다. 상담원이 바로 적용할 수 있는 구체적인 대안을 제시해야 진정한 코칭 가치가 있습니다.

---

### 2.3 Operational Health (운영 건전성)

#### OH-1. API 비용 효율성 (Cost per Analysis)

| 항목 | 내용 |
|------|------|
| **정의** | 분석 1건당 소요되는 API 비용 |
| **공식** | `총 API 비용 / 총 분석 건수` |
| **목표** | ≤$0.05 (텍스트), ≤$0.10 (음성 포함) |
| **측정 주기** | 주간 |
| **데이터 소스** | OpenAI 사용량 대시보드 |

**선정 이유**:
> 제품화를 위해서는 비용 효율성이 필수입니다. 건당 비용이 높으면 고객사에 합리적인 가격으로 제공할 수 없습니다.

---

#### OH-2. 시스템 가용성 (Uptime)

| 항목 | 내용 |
|------|------|
| **정의** | 시스템이 정상 작동한 시간 비율 |
| **공식** | `(총 시간 - 다운타임) / 총 시간 × 100` |
| **목표** | ≥99% |
| **측정 주기** | 월간 |
| **데이터 소스** | 모니터링 도구 (UptimeRobot 등) |

---

#### OH-3. 일간 활성 사용자 (DAU)

| 항목 | 내용 |
|------|------|
| **정의** | 하루에 1건 이상 분석을 수행한 고유 사용자 수 |
| **목표** | 성장 추세 유지 |
| **측정 주기** | 일간 |
| **데이터 소스** | 시스템 로그 |

---

## 3. KPI 대시보드 설계

### 3.1 Executive Summary View

```
┌─────────────────────────────────────────────────────────────────────────────┐
│                    Counsel Coach - KPI Dashboard                            │
│                    2026년 1월 Weekly Report                                 │
├─────────────────────────────────────────────────────────────────────────────┤
│                                                                              │
│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐             │
│  │  품질 향상률     │  │  코칭 시간 절감  │  │  분석 정확도     │             │
│  │                 │  │                 │  │                 │             │
│  │    +18%        │  │    -72%        │  │    87%         │             │
│  │    🟢 목표달성   │  │    🟢 목표달성   │  │    🟢 목표달성   │             │
│  │   (목표: 15%)   │  │   (목표: 70%)   │  │   (목표: 85%)   │             │
│  └─────────────────┘  └─────────────────┘  └─────────────────┘             │
│                                                                              │
│  ┌─────────────────┐  ┌─────────────────┐  ┌─────────────────┐             │
│  │  완료율         │  │  처리 시간      │  │  건당 비용       │             │
│  │                 │  │                 │  │                 │             │
│  │    97%         │  │    18초        │  │   $0.03        │             │
│  │    🟢 정상      │  │    🟢 양호      │  │    🟢 효율적    │             │
│  └─────────────────┘  └─────────────────┘  └─────────────────┘             │
│                                                                              │
└─────────────────────────────────────────────────────────────────────────────┘
```

### 3.2 상태 기준

| 상태 | 색상 | 기준 |
|------|------|------|
| 🟢 양호 | 녹색 | 목표 100% 이상 달성 |
| 🟡 주의 | 노란색 | 목표 80-99% 달성 |
| 🔴 위험 | 빨간색 | 목표 80% 미만 |

---

## 4. 측정 및 리포팅 계획

### 4.1 측정 주기별 활동

| 주기 | 지표 | 담당자 | 액션 |
|------|------|--------|------|
| **실시간** | 처리 시간, 완료율 | 시스템 | 자동 모니터링, 알림 |
| **일간** | DAU, 분석 건수 | 운영팀 | 이상치 확인 |
| **주간** | 비용 효율성, 가용성 | 운영팀 | 주간 리뷰 |
| **월간** | 품질 향상률, 정확도 | PM | 월간 리포트 |

### 4.2 알림 기준

| 지표 | 알림 조건 | 대응 |
|------|----------|------|
| 완료율 | <90% (1시간 기준) | 시스템 점검 |
| 처리 시간 | P95 > 60초 | 성능 최적화 |
| 비용 | 일 예산 80% 도달 | 사용량 분석 |
| 가용성 | 5분 이상 다운 | 즉시 복구 |

---

## 5. 지표 간 관계도

```
                              ┌─────────────────┐
                              │   상담 품질     │
                              │   향상률        │ ◄── 최종 목표
                              │   (BI-1)       │
                              └────────┬────────┘
                                       │
                    ┌──────────────────┼──────────────────┐
                    │                  │                  │
                    ▼                  ▼                  ▼
           ┌────────────────┐ ┌────────────────┐ ┌────────────────┐
           │   분석 정확도   │ │ 피드백 실행    │ │  자기주도      │
           │   (PQ-1)       │ │  가능성        │ │  학습률        │
           │                │ │  (PQ-4)       │ │  (BI-3)       │
           └────────┬───────┘ └───────┬────────┘ └───────┬────────┘
                    │                 │                  │
                    │      신뢰성과 유용성 확보           │
                    │                 │                  │
                    ▼                 ▼                  ▼
           ┌────────────────┐ ┌────────────────┐ ┌────────────────┐
           │   완료율       │ │   처리 시간    │ │   DAU          │
           │   (PQ-2)       │ │   (PQ-3)       │ │   (OH-3)       │
           │                │ │                │ │                │
           └────────┬───────┘ └───────┬────────┘ └───────┬────────┘
                    │                 │                  │
                    └─────────────────┼──────────────────┘
                                      │
                                      ▼
                              ┌────────────────┐
                              │   비용 효율성   │
                              │   (OH-1)       │ ◄── 제약 조건
                              └────────────────┘
```

---

## 6. 벤치마크 및 목표 설정 근거

### 6.1 분석 정확도 85% 근거

| 비교 대상 | 정확도 | 비고 |
|-----------|--------|------|
| 전문가 간 일치율 | 80-85% | 평가자 간 편차 존재 |
| 유사 AI 솔루션 | 75-80% | 업계 평균 |
| **목표** | **85%** | 전문가 수준 |

### 6.2 코칭 시간 절감 70% 근거

**기존 코칭 프로세스 시간 분석**:
```
1. 상담 녹취/로그 확인: 30분
2. 개선점 정리: 20분
3. 피드백 문서 작성: 15분
4. 코칭 미팅: 30분
──────────────────────────
합계: 95분/건

AI 도입 후:
1. AI 분석 검토: 5분
2. 추가 코멘트: 5분
3. 코칭 미팅: 20분
──────────────────────────
합계: 30분/건

절감률: (95-30)/95 = 68% → 목표 70%
```

### 6.3 비용 목표 $0.05 근거

**단건 비용 분석**:
```
GPT-4o 입력: 2,000 tokens × $0.0025/1K = $0.005
GPT-4o 출력: 800 tokens × $0.01/1K = $0.008
버퍼 (재시도 등): 20%
──────────────────────────
합계: ~$0.015-0.02

여유분 포함 목표: $0.05
```

---

## 7. 지속적 개선 프로세스

### 7.1 월간 KPI 리뷰 프로세스

```
Week 1: 데이터 수집 및 정리
   ↓
Week 2: 분석 및 인사이트 도출
   ↓
Week 3: 개선 방안 수립
   ↓
Week 4: 실행 및 모니터링
   ↓
반복
```

### 7.2 지표 조정 기준

- **상향 조정**: 3개월 연속 목표 달성 시
- **하향 조정**: 외부 환경 변화 (API 가격 인상 등)
- **폐기**: 6개월간 의미 있는 인사이트 없음

---

## 8. 결론

이 KPI 시트는 **"실제 문제를 해결했는가"**를 중심으로 설계되었습니다.

**핵심 메시지**:
1. 분석 정확도가 높아야 → 신뢰할 수 있고
2. 피드백이 실행 가능해야 → 실제로 적용하고
3. 상담 품질이 향상되어야 → 비즈니스 가치가 증명됩니다

채널톡 FDE로서 이 시스템이 **고객사의 실제 문제를 해결하고, 제품화 가능한 프로토타입**임을 증명하는 것이 목표입니다.

---

**문서 끝**
